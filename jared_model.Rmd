---
title: "jared_model"
author: "Jared Petry"
date: "2023-03-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For this quarter's final lab, you will be using the knowledge of machine learning that you have gained this quarter to training models to predict dissolved inorganic carbon in water samples collected by the California Cooperative Oceanic Fisheries Investigations program (CalCOFI).

## Your Task:
- Acquire domain knowledge. (Dr. Satterthwaite's presentation)
- Explore the data.
- Preprocessing.
- Choose a model algorithm.
- Tune relevant parameters (Cross validation).
- Submit your prediction.

```{r include=FALSE}
library(caret) 
library(tidymodels) 
library(tidyverse)
library(dplyr) 
library(gbm)
library(xgboost)
library(ggpubr)
library(tictoc)
library(vip)
library(Hmisc)
library(censored)
library(pec)
```


## Read in the data: 

This dataset was downloaded from the CalCOFI data portal. Bottle and cast data was downloaded and merged, then relevant variables were selected.

You will use the data contained in the train.csv file to train a model that will predict dissolved inorganic carbon (DIC) content in the water samples.

```{r}
dic_train <- read_csv("train.csv") |> select(-...13) # take out blank column
dic_test <- read_csv("test.csv")
```

Here's a short description of each variables: 

NO2uM - Micromoles Nitrite per liter of seawater
NO3uM - Micromoles Nitrate per liter of seawater
NH3uM - Micromoles Ammonia per liter of seawater
R_TEMP - Reported (Potential) Temperature in degrees Celsius
R_Depth - Reported Depth (from pressure) in meters
R_Sal - Reported Salinity (from Specific Volume Anomoly, MÂ³/Kg)
R_DYNHT - Reported Dynamic Height in units of dynamic meters (work per unit mass)
R_Nuts - Reported Ammonium concentration
R_Oxy_micromol.Kg - Reported Oxygen micromoles/kilogram
PO4uM - Micromoles Phosphate per liter of seawater
SiO3uM - Micromoles Silicate per liter of seawater
TA1.x - Total Alkalinity micromoles per kilogram solution
Salinity1 - Salinity
Temperature_degC - Temp
DIC - Outcome

**Heads up: one variable is differing in the train set: TA1.x in train set and TA1 in test set... Also column 13 is blank so I am removing it from the start

### Data exploration: 

```{r}
# let's see which variables are most correlated with variable DIC 
corr <- rcorr(as.matrix(dic_train))
corr$r

```
As we can see from this correlation matrix, the variables that are highly correlated with DIC are: 
- NO3uM 0.97985048
- R_TEMP -0.936951708
- R_Depth 0.55575020
- R_Sal -0.963750900
- R_DYNHT 0.79719608
- R_Oxy_micromol.Kg   -0.97886763 
- PO4uM 0.994955284
- SiO3uM 0.90876340
- TA1.x 0.852645604    
- Salinity1 0.940914237
- Temperature_degC -0.936781353

Variables that are NOT highly correlated with DIC: 
- id 
- Lat_Dec 
- Lon_Dec 
- NO2uM
- NH3uM
- R_Nuts



## Pick a model: 

Here are the types of models that we have worked with in this class: 
linear regression 
- lab 1: used to predict the price of a pumpkin (linear_reg() function)
regularized multivariate polynomial regression 
- used the same as above with step_poly and poly_spec?? I am confused how different this would be or if this would be possible with many variables
classification and logistic regression 
- not applicable here because we are predicting a continuous variable
k nearest neighbors 
- could be a good option?

decision tree 
bagged forest
random forest 
boosted trees

We are not doing classification, we are trying to predict an actual number for DIC, so 

### Let's try a K-nearest neighbor model 
- NO3uM 0.97985048
- R_TEMP 
- R_Depth 
- R_Sal 
- R_DYNHT 
- R_Oxy_micromol.Kg   -0.97886763 
- PO4uM 0.994955284
- SiO3uM 
- TA1.x     
- Salinity1 
- Temperature_degC 
```{r}
# create a recipe (this time only using select variables! the ones that are highly correlated with DIC)
dic_recipe <- recipe(DIC ~ NO3uM + R_Oxy_micromol.Kg + PO4uM, data = dic_train) |> 
  step_normalize(all_numeric(), -all_outcomes()) |>  # I took this step out and results were unhanged... maybe take out? 
  prep() 
# potentially add some pre-processing steps?? all the data are already numeric
# I think the knn model like normalized data

# bake the recipe
baked_dic <- bake(dic_recipe, dic_train)

knn_spec_tune <- nearest_neighbor(neighbors = tune()) |> 
  set_engine("kknn") |> 
  set_mode("regression")
knn_spec_tune

# create cross validation folds 
set.seed(1738)
folds <- vfold_cv(data = dic_train, 
                  v = 10,
                  strata = DIC)

# build a workflow
knn_workflow <- workflow() |> 
  add_model(knn_spec_tune) |> 
  add_recipe(dic_recipe) 

# now fit the resamples
set.seed(345)
fit_knn_cv <- knn_workflow |> 
  tune_grid(
    folds,
    grid = data.frame(neighbors = c(1, 5, 10, seq(20, 100, 10))) # this will make it try running on all different folds, for example we are keeping it                                             simple for run time. sample different from 1-100
  )

# Check the performance with collect_metrics()
fit_knn_cv %>% collect_metrics()

# show the best number of neighborsfor fitting to our cv folds
show_best(fit_knn_cv)
# ---- looks like 10 neighbors is best!

# now we can finalize our workflow
final_wf <- 
  knn_workflow |> 
  finalize_workflow(select_best(fit_knn_cv))
final_wf

# make a final fit 
final_fit <- final_wf |> last_fit(dic_test)
# finally, make predictions on the test data  
dic_pred_on_test <- predict(k_10_mod, dic_test)

# welp, this code doesn't run but I'm getting like over 10 RMSE and that's not very good so I don't think KNN is the way to go since there's not anything left for me to tune other than K
```
Using all variables, the RMSE was over 10 
Using these variables (those correlated over 50 percent, top ten or so), the RMSE was 6.240940
Using these variables (those correlated over 90 percent, top 8), the RMSE was 6.131425
Using top 7 variables the RMSE was 6.165918	
using top 6 6.052055 (NO3uM, R_TEMP, R_Sal, R_Oxy_micromol.Kg, PO4uM, Salinity1)
using top 5 5.920321 (NO3uM, R_Sal, R_Oxy_micromol.Kg, PO4uM, Salinity1)
using top 4 6.025363	
using top 3 not sick

NO3uM 0.97985048
- R_TEMP 
- R_Depth 
- R_Sal 
- R_DYNHT 
- R_Oxy_micromol.Kg   -0.97886763 
- PO4uM 0.994955284
- SiO3uM 
- TA1.x     
- Salinity1 0.940914237
- Temperature_degC 


### Let's try a simple decision tree: 

```{r}
# create model specification 
tree_spec_tune <- decision_tree(
  cost_complexity = tune(), 
  tree_depth = tune(), 
  min_n = tune()
) |> 
  set_engine("rpart") |> 
  set_mode("regression") # later on, try "censored regression"

# create a recipe
tree_recipe <- recipe(DIC ~ NO3uM + R_TEMP + R_Sal + R_Oxy_micromol.Kg + PO4uM + Salinity1, 
                      data = dic_train) |> 
  step_normalize(all_numeric(), -all_outcomes()) |>  # I took this step out and results were unhanged... maybe take out? 
  prep() 

# create a tuning grid for our hyperparameters
tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 10) # how many levels will the tune try
tree_grid

# create a workflow
wf_tree_tune <- workflow() |> 
  add_recipe(tree_recipe) |> 
  add_model(tree_spec_tune)

#set up k-fold cv. This can be used for all the algorithms
set.seed(1738)
tree_folds = dic_train |> 
  vfold_cv(v = 10)
tree_folds

# have the cores run in parallel so it doesn't take as long to run
doParallel::registerDoParallel() #build trees in parallel
tree_rs <- tune_grid(
  tree_spec_tune, # model specification
  DIC ~ NO3uM + R_TEMP + R_Sal + R_Oxy_micromol.Kg + PO4uM + Salinity1,  # features to use
  resamples = tree_folds, # put the resamples that we created above 
  grid = tree_grid, # which grid
  metrics = metric_set(rmse)  # which combination is the best 
)
tree_rs

autoplot(tree_rs) + theme_light()

# is you want to actually see the best values for accuracy
show_best(tree_rs) 

# note: using the censored regression option in the recipe caused all models to fail.. maybe look into this later

```

### Let's try a boosted tree model: 
```{r}
# bagged decision tree recipe: 
bag_tree_recipe <- recipe(DIC ~ NO3uM + R_TEMP + R_Sal + R_Oxy_micromol.Kg + PO4uM + Salinity1, 
                      data = dic_train) |> 
  step_normalize(all_numeric(), -all_outcomes()) |>  # I took this step out and results were unhanged... maybe take out? 
  prep() 

# create model specification 
bag_tree_spec_tune <- bag_tree(
  cost_complexity = tune(), 
  tree_depth = tune(), 
  min_n = tune()) |> 
  set_engine("rpart", times = 1000) |> 
  set_mode("censored regression")
  

set.seed(1738)
bag_tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 10) # how many levels will the tune try

bag_tree_grid

# bundle into workflow 
wf_bag_tree_tune <- workflow() |> 
  add_recipe(bag_tree_recipe) |> 
  add_model(bag_tree_spec_tune)

# determine best combination of tuned hyperparamters
doParallel::registerDoParallel() #build trees in parallel
#200s
bag_tree_rs <- tune_grid(
  wf_bag_tree_tune, # model specification
  DIC ~ NO3uM + R_TEMP + R_Sal + R_Oxy_micromol.Kg + PO4uM + Salinity1,  # features to use
  resamples = song_cv, # put the resamples that we created above 
  grid = tree_grid, # which grid
  metrics = metric_set(rmse)  # which combination is the best 
)

bag_tree_rs
show_best(bag_tree_rs) 
```

Notes: what is censored regression.. why did it cause the models to fail in the decision tree model...
- should I use 'bake()'? or just prep() like I have been ... when and why would i use those and would it just influence something about functions within the model or actual performance of the model?
- I forgot to specify features to use in the decision tree maybe this has something to do with it







